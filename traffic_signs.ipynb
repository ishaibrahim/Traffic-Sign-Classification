{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install scikit-learn scikit-image\n",
    "\n",
    "# Captured output on this cell to maintain notebook tidiness :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Traffic Signs\n",
    "\n",
    "The goal of this notebook is to process traffic sign images and classify them using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data \n",
    "The data for this project is a series of images of traffic signs, captured under different real life conditions such as normal lighting, poor lighting, obstructions and pictures of traffic signs that are far away from the camera. The pictures have been pre-processed, in that they are cropped, scaled, and loaded into a python object. They have corresponding sign labels. The pre-defined list of labels for recognition is provided as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip\n",
    "import zipfile\n",
    "data = \"data/\"\n",
    "with zipfile.ZipFile(data+\"data_1.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(data)\n",
    "with zipfile.ZipFile(data+\"data_2.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(data)\n",
    "with zipfile.ZipFile(data+\"data_3.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Speed limit (20km/h)',\n",
       " 1: 'Speed limit (30km/h)',\n",
       " 2: 'Speed limit (50km/h)',\n",
       " 3: 'Speed limit (60km/h)',\n",
       " 4: 'Speed limit (70km/h)',\n",
       " 5: 'Speed limit (80km/h)',\n",
       " 6: 'End of speed limit (80km/h)',\n",
       " 7: 'Speed limit (100km/h)',\n",
       " 8: 'Speed limit (120km/h)',\n",
       " 9: 'No passing',\n",
       " 10: 'No passing for vehicles over 3.5 metric tons',\n",
       " 11: 'Right-of-way at the next intersection',\n",
       " 12: 'Priority road',\n",
       " 13: 'Yield',\n",
       " 14: 'Stop',\n",
       " 15: 'No vehicles',\n",
       " 16: 'Vehicles over 3.5 metric tons prohibited',\n",
       " 17: 'No entry',\n",
       " 18: 'General caution',\n",
       " 19: 'Dangerous curve to the left',\n",
       " 20: 'Dangerous curve to the right',\n",
       " 21: 'Double curve',\n",
       " 22: 'Bumpy road',\n",
       " 23: 'Slippery road',\n",
       " 24: 'Road narrows on the right',\n",
       " 25: 'Road work',\n",
       " 26: 'Traffic signals',\n",
       " 27: 'Pedestrians',\n",
       " 28: 'Children crossing',\n",
       " 29: 'Bicycles crossing',\n",
       " 30: 'Beware of ice/snow',\n",
       " 31: 'Wild animals crossing',\n",
       " 32: 'End of all speed and passing limits',\n",
       " 33: 'Turn right ahead',\n",
       " 34: 'Turn left ahead',\n",
       " 35: 'Ahead only',\n",
       " 36: 'Go straight or right',\n",
       " 37: 'Go straight or left',\n",
       " 38: 'Keep right',\n",
       " 39: 'Keep left',\n",
       " 40: 'Roundabout mandatory',\n",
       " 41: 'End of no passing',\n",
       " 42: 'End of no passing by vehicles over 3.5 metric tons'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sign names\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/signnames.csv\")\n",
    "signnames = pd.Series(df.SignName.values,index=df.ClassId).to_dict()\n",
    "signnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "import pickle\n",
    "#load pickle for training data\n",
    "signimages = pickle.load( open( data+\"train.p\", \"rb\" ) )\n",
    "\n",
    "#load pickle for validation\n",
    "signimages_validation = pickle.load( open( data+\"valid.p\", \"rb\" ) )\n",
    "\n",
    "#load pickle for testing\n",
    "signimages_test = pickle.load( open( data+\"test.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring The Data\n",
    "\n",
    "To get an idea of what the pictures of traffic signs in the dataset look like, we can preview any image in the training data, as the pickle for the training data is already loaded above. Exploring the structure of the data provided tells us that the pictures of traffic signs correspond to the dictionary key \"features\". \n",
    "\n",
    "Previewing an image at random can therefore be done by calling on a picture by its positon inside the \"features\" key. Then we look at the corresponding sign name, and the indexing within the image that carries matrixes for the RGB values that correspond with each pixel. Exploring the indexing is not a neccessary step, but it is preferred as understanding the data in detail is useful to determine which features can be easily extracted from the pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['coords', 'labels', 'features', 'sizes'])\n"
     ]
    }
   ],
   "source": [
    "print(signimages.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a General caution sign.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import cv2\n",
    "\n",
    "inx = 20500\n",
    "\n",
    "#inserting a pixel in this image to check which way the pixels are labelled\n",
    "#signimages['features'][inx][5][20] = [0,255,0]\n",
    "\n",
    "\n",
    "plt.imshow(signimages['features'][inx])\n",
    "print(f\"The image shows a {signnames[signimages['labels'][inx]]} sign.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110  27  24]\n"
     ]
    }
   ],
   "source": [
    "# Printing rgb values for a pixel in the above picture. This is to help me identify the indexing in the image object.\n",
    "print(signimages['features'][inx][27][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Based on the above exploration of the data, there are a few possible features to be extracted. \n",
    "\n",
    "1. Shape: A lot of the signs have distinct shapes like triangles and circles. \n",
    "2. Color: Most signs have distinct solid colors, often blue, white, black, and red.\n",
    "\n",
    "Since the goal here is to build an accurate classifier model with the best features, we have a few choices for feature extraction. A feature descriptor that considers both shape and edge information as well as color information is a HOG (Histogram of Oriented Gradients). \n",
    "\n",
    "The feature data needs to be included in the dataframes for training, validation and testing data, so the best method to do so is to create a function that takes in the python object with the source data and some HOG parameters.By taking the HOG parameters as arguments they can be easily adjusted o find the amunt of data features that can give the best model.\n",
    "\n",
    "For a Histogram of Oriented Gradients, the parameters I find important are:\n",
    "\n",
    "1. The amount of pixels in a cell block- less pixels per cell block means more data generated- more data is not necessarily always the best approach, but the pictures in this dataset are quite small to begin with, so less pixels per cell-block is the better approach. \n",
    "2. The number of orientations- simply put, the amount of bins for the histogram that measure the direction of the gradient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________________________\n",
    "\n",
    "############# Using HOG to extract features #################\n",
    "#____________________________________________________________\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "#create a function to generate a dataframe \n",
    "def generate_dataframe(imgs, \n",
    "                       orientations = 8, \n",
    "                       pixels_per_cell = (4,4)): #orientatins and pixels per cell given a default value\n",
    "    hog_data = []\n",
    "    for inx in range(len(imgs[\"features\"])):\n",
    "        image = imgs [\"features\"][inx]\n",
    "        hog_description = hog(image, \n",
    "                              orientations = orientations, \n",
    "                              pixels_per_cell= pixels_per_cell, \n",
    "                              cells_per_block = (2, 2), \n",
    "                              channel_axis= 2)  #why 2? because colors are in the third index\n",
    "        label = np. array([imgs[\"labels\"][inx]])\n",
    "        hog_data.append(np.concatenate((label, hog_description)))\n",
    "\n",
    "#convert list of rows in dataframe \n",
    "    ret_df = pd.DataFrame(hog_data)\n",
    "    return ret_df.rename(columns = {0:\"target\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this code flexible and to make it easier to test out other parameter combinations, I write it so all the processing is done dynamically based on the input list of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOG parameter combinations to be tested\n",
    "list_of_parameters = [\n",
    "    { \"orientations\": 8, \"pixels_per_cell\": (4,4) },\n",
    "    { \"orientations\": 16, \"pixels_per_cell\": (4,4) },\n",
    "    { \"orientations\": 8, \"pixels_per_cell\": (8,8) },\n",
    "    { \"orientations\": 16, \"pixels_per_cell\": (8,8) }\n",
    "]\n",
    "\n",
    "#list comprehension to create list of dataframes for train/validation/test for HOG parameter combinations\n",
    "train_dataframes = [ generate_dataframe(signimages, params[\"orientations\"], params[\"pixels_per_cell\"]) for params in list_of_parameters ]\n",
    "\n",
    "validation_dataframes = [ generate_dataframe(signimages_validation, params[\"orientations\"], params[\"pixels_per_cell\"]) for params in list_of_parameters ]\n",
    "\n",
    "test_dataframes = [ generate_dataframe(signimages_test, params[\"orientations\"], params[\"pixels_per_cell\"]) for params in list_of_parameters ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X Y split for train,validation and test dataframes.\n",
    "\n",
    "train_xy_dataframes = [ (train_dataframe.drop(['target'], axis=1), train_dataframe['target']) for train_dataframe in train_dataframes ]\n",
    "\n",
    "validate_xy_dataframes = [ (validate_dataframe.drop(['target'], axis=1), validate_dataframe['target']) for validate_dataframe in validation_dataframes ]\n",
    "\n",
    "test_xy_dataframes = [ (test_dataframe.drop(['target'], axis=1), test_dataframe['target']) for test_dataframe in test_dataframes ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Classifier \n",
    "\n",
    "A Support Vector Classifier is a good choice for this dataset, as it performs well in handling complex boundaries between classes of items, especially when they have similar shapes and colors but different symbols, as is usually the case in traffic signs. Below we train a few models on the datasets produced from changing different HOG parameters to determine the best accuracy level and the best accuracy retention when the models are tested on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________________________\n",
    "\n",
    "########### Using Support Vector Classifier ###############\n",
    "#____________________________________________________________\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Creating a list of models trained on the list of X and Y data we just made in the above cell\n",
    "\n",
    "svcs = []\n",
    "for train_x, train_y in train_xy_dataframes:\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc.fit(train_x, train_y)\n",
    "    svcs.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the list of SVC models based on the different HOG parameters to predict the traffic sign labels on validation data\n",
    "validation_accuracy_scores = []\n",
    "\n",
    "for (validate_x, validate_y), svc in zip(validate_xy_dataframes, svcs):\n",
    "    y_pred = svc.predict(validate_x)\n",
    "    accuracy = accuracy_score(validate_y, y_pred)\n",
    "    validation_accuracy_scores.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC model on validation data with HOG_8_(4, 4) has an accuracy score of 90.02% \n",
      "SVC model on validation data with HOG_16_(4, 4) has an accuracy score of 90.14% \n",
      "SVC model on validation data with HOG_8_(8, 8) has an accuracy score of 78.84% \n",
      "SVC model on validation data with HOG_16_(8, 8) has an accuracy score of 80.57% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataframe_names = [ f\"HOG_{params['orientations']}_{params['pixels_per_cell']}\" for params in list_of_parameters ] \n",
    "\n",
    "#printing SVC model prediction accuracy for each model type\n",
    "for score, name in zip(validation_accuracy_scores, dataframe_names):\n",
    "    print(f\"SVC model on validation data with {name} has an accuracy score of {score *100:.2f}% \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the list of SVC models based on the different HOG parameters to predict the traffic sign labels on test data\n",
    "test_accuracy_scores = []\n",
    "\n",
    "for (test_x, test_y), svc in zip(test_xy_dataframes, svcs):\n",
    "    y_pred = svc.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    test_accuracy_scores.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC model on testing data with HOG_8_(4, 4) features has an accuracy score of 88.51% \n",
      "SVC model on testing data with HOG_16_(4, 4) features has an accuracy score of 88.03% \n",
      "SVC model on testing data with HOG_8_(8, 8) features has an accuracy score of 78.11% \n",
      "SVC model on testing data with HOG_16_(8, 8) features has an accuracy score of 78.86% \n"
     ]
    }
   ],
   "source": [
    "#printing accuracy score of each model on testing data\n",
    "for score, name in zip(test_accuracy_scores, dataframe_names):\n",
    "    print(f\"SVC model on testing data with {name} features has an accuracy score of {score *100:.2f}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "A Linear SVC model run with more feature data extracted from image pixels produce a higher accuracy This corresponds to the Pixels-per-Cell parameter in the HOG feature extraction. A small square of Pixels-per-Cell results in more information extracted from the whole image, as more pixels are individually assessed for feature information.\n",
    "\n",
    "Increasing the Orientation parameter in feature extraction, which corresponds to information about the direction of the gradients has less impact on the accuracy of the model. The worst model performance is from the model that recieved the least amount of features in total. \n",
    "\n",
    "### Best Choice: Model A\n",
    "Model A (Linear SVC, HOG: 8 Orientations, Pixels per Cell 4x4) has the highest prediction accuracy and a low generalization gap compared to Model B, which has a marginally better accuracy score but a far worse generalization gap, which means it could perform better in future use as well when exposed to further unseen data.\n",
    "\n",
    "| Model  | Test Accuracy (%) | Unseen Dataset Accuracy (%) | Generalization Gap |\n",
    "|--------|-----------------|-----------------------------|---------------------|\n",
    "| **A**  | 90.02          | 88.51                        | **1.51**           |\n",
    "| **B**  | 90.14          | 88.03                        | **2.11**           |\n",
    "| **C**  | 78.84          | 78.11                        | **0.73**           |\n",
    "| **D**  | 80.57          | 78.86                        | **1.71**           |\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
